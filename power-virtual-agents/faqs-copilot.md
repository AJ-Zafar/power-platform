---
title: FAQ for copilot
description: This FAQ provides information about the AI technology used in Power Virtual Agents, along with key considerations and details about how the AI is used, how it was tested and evaluated, and any specific limitations.
ms.date: 7/13/2023
ms.custom: 
  - responsible-ai-faqs
ms.topic: article
author: iaanw
ms.author: iawilt
ms.reviewer: iawilt
---

# FAQ for copilot

These frequently asked questions (FAQ) describe the AI impact of [Product]'s copilot feature.

## What is copilot?

[Describe the system in plain English. What type of system or feature is this? What does it do? At a high level, what does the system or feature take as input? What kind of outputs does the system or feature produce?]

## What are copilot's capabilities?

[Building on the previous question, provide semi-technical, high-level information on how the system or feature offers functionality for various uses.]

## What is copilot's intended use?

[Explain intended use(s), as identified in your Impact Assessment.]

## How was copilot evaluated? What metrics are used to measure performance?

[Provide evidence of system or feature accuracy and performance, and, when applicable, a description of the extent to which these results are generalizable across use cases that were not part of the evaluation.]

## What are the limitations of copilot? How can users minimize the impact of limitations when using copilot?

[See Impact Assessment. Describe the known limitations of the system or feature including uses for which the system was not designed or evaluated. Discuss steps that the user can take to minimize errors and the impact of trade-offs for the user.]

## What operational factors and settings allow for effective and responsible use of copilot?

[Describe the operational factors and ranges within which the system is expected to perform reliably and safely. List the choices that end users can make (e.g., customization, settings, etc.), with a description of how those choices may impact system behavior in the real world.]

## See also

- [Feature page]([Link])








=================

## AI response generation training, model, and usage notes

This FAQ answers common questions about the AI that is used when creating new topics, or modifying existing topics, in Power Virtual Agents.


### Does the capability produce perfect topics?   

Topics generated by the **Copilot** capability are not always perfect, and may not accurately reflect the logic you wanted to implement. 

The system is designed to generate a single bot topic from a human-written description. We have implemented mitigations to filter out irrelevant and offensive language from appearing in the configured topic, and the system is designed not to respond when offensive language is detected. 

We also monitor output and the feedback that bot users provide to continually improve our content filters.

These filters and mitigations are not foolproof.

You should always test and review your bots before publishing them.

### How was the capability evaluated? What metrics are used to measure performance?

The capability was evaluated on a collection of manually curated prompt-and-topic datasets, covering common, edge-case, and offensive content, as well as synthetic generation.

During evaluation, topics generated from the capability were manually reviewed and scored for relevance to the input prompt, usefulness, and offensiveness. 

## Fairness and broader impact

### Will the capability work as well using languages other than English?

The system only supports English. Inaccurate responses may be returned when users converse with the system in languages other than English.

## Privacy

### What data does the capability collect? How is the data used?

The capability collects user prompts, the returned configured Topics, and any feedback you provide.

We use this data to evaluate and improve the quality of the capability. More information on what data is collected is available in the [terms](https://go.microsoft.com/fwlink/?linkid=2236010).

## Disable Copilot in Power Virtual Agents

Admins can disable Copilot for their organization by starting a support request with Microsoft.

## Reporting Concerns

### How can I report concerns about Copilot?

If you have any concerns (such as those relating to content policies or codes of conduct) about the Copilot feature, you can raise them by emailing us at pvareport@microsoft.com. We will aim to respond to you within 2 business days.
